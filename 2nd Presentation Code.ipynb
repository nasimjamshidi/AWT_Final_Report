{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import  math\n",
    "from sklearn.model_selection import cross_validate,train_test_split\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from numpy import genfromtxt\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = pd.read_csv(\"encode.csv\")\n",
    "clip = pd.read_csv(\"clip.csv\") \n",
    "scenechange = pd.read_csv(\"scene_change.csv\") \n",
    "scenechange.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Add prefix to distinguish the tables after merging  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip=clip.add_prefix('clip_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate scene change percentage in one second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_df = pd.DataFrame(columns=['clip_id','averagescenechange'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenechange = scenechange[~scenechange['clip_id'].isnull()]\n",
    "#scenechange.dropna(how='any',axis=0)\n",
    "clip_id = scenechange['clip_id'].unique()\n",
    "j = 0;\n",
    "for i in clip_id:\n",
    "    j = j + 1;\n",
    "    scene_df.loc[j] = [i , np.sum(scenechange[scenechange['clip_id']==i]['percentage'])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Get the last part of the names in 'clip_filename' for simplification  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip= clip.dropna(subset=['clip_filename'])\n",
    "size=clip['clip_filename'].shape[0]\n",
    "for i in range(size):\n",
    "    txt=clip['clip_filename'][i]\n",
    "    out = txt.split(\"/\")\n",
    "    clip['clip_filename'][i]=out[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change the form of values from fractional to integer in 'clip_frame_rate' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size=clip['clip_frame_rate'].shape[0]\n",
    "for i in range(size):\n",
    "    txt=clip['clip_frame_rate'][i]\n",
    "    out = txt.split(\"/\")\n",
    "    clip['clip_frame_rate'][i]=float(out[0])/float(out[1])\n",
    "clip.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Add prefix to distinguish the tables after merging   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode=encode.add_prefix('encode_')\n",
    "#encode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merge the tables Clip and Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_clip=encode.merge(clip, left_on='encode_clip_id', right_on='clip_id',how='left')\n",
    "encode_clip.head()\n",
    "encode_clip_scene = encode_clip.merge(scene_df,left_on='clip_id', right_on='clip_id',how='left')\n",
    "#encode_clip.shape[1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Calculate the resolution, width times hight  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_WidthHeight= encode_clip_scene['encode_width']*encode_clip_scene['encode_height']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As the clips duration are not the same, by dividing the 'averagescenechange' by 'clip_duration', the average scenechange for one second is calculated  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenechange_avg= encode_clip_scene['averagescenechange']/encode_clip_scene['clip_duration']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Select the desired features from the merged tables  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.DataFrame({'encode_WidthHeight': encode_WidthHeight,'clip_filename':encode_clip['clip_filename'], 'encode_crf': encode_clip['encode_crf'], 'encode_bitrate_video': encode_clip['encode_bitrate_video'], 'encode_vmaf': encode_clip['encode_vmaf'], 'clip_duration': encode_clip['clip_duration'], 'clip_size': encode_clip['clip_size'], 'clip_bitrate_total': encode_clip['clip_bitrate_total'], 'clip_bitrate_video': encode_clip['clip_bitrate_video'], 'clip_height': encode_clip['clip_height'],'clip_frame_rate':encode_clip['clip_frame_rate']})\n",
    "df=pd.DataFrame({'averagescenechange': scenechange_avg, 'encode_WidthHeight': encode_WidthHeight,'clip_filename':encode_clip_scene['clip_filename'], 'encode_crf': encode_clip_scene['encode_crf'], 'encode_bitrate_video': encode_clip_scene['encode_bitrate_video'], 'encode_vmaf': encode_clip_scene['encode_vmaf'], 'clip_duration': encode_clip_scene['clip_duration'], 'clip_size': encode_clip_scene['clip_size'], 'clip_height': encode_clip_scene['clip_height'],'clip_frame_rate':encode_clip_scene['clip_frame_rate']})\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clip_frame_rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply the method ITU-T P.1401 on 'encode_bitrate_video' to remove the extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=df['encode_bitrate_video'].shape[0]\n",
    "IQR=df['encode_bitrate_video'].describe()[6]-df['encode_bitrate_video'].describe()[4]\n",
    "IQR2=IQR*3\n",
    "threshold=df['encode_bitrate_video'].describe()[6]+IQR2\n",
    "for i in range(shape):\n",
    "    if(df.iloc[i, 7:8].values[0] >= threshold):\n",
    "        df.iloc[i, 7:8]=np.nan\n",
    "        #df.at[i, 3:4] = 0\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Apply the method ITU-T P.1401 on 'averagescenechange' to remove the extreme outliers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=df['averagescenechange'].shape[0]\n",
    "IQR=df['averagescenechange'].describe()[6]-df['averagescenechange'].describe()[4]\n",
    "IQR2=IQR*3\n",
    "threshold=df['averagescenechange'].describe()[6]+IQR2\n",
    "for i in range(shape):\n",
    "    if(df.iloc[i, 0:1].values[0] >= threshold):\n",
    "        df.iloc[i, 0:1]=np.nan\n",
    "        #df.at[i, 3:4] = 0\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apply the method ITU-T P.1401 on 'clip_size' to remove the extreme outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=df['clip_size'].shape[0]\n",
    "IQR=df['clip_size'].describe()[6]-df['clip_size'].describe()[4]\n",
    "IQR2=IQR*3\n",
    "threshold=df['clip_size'].describe()[6]+IQR2\n",
    "for i in range(shape):\n",
    "    if(df.iloc[i, 5:6].values[0] >= threshold):\n",
    "        df.iloc[i, 5:6]=np.nan\n",
    "        #df.at[i, 3:4] = 0\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Apply the method ITU-T P.1401 on 'clip_duration' to remove the extreme outliers  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=df['clip_duration'].shape[0]\n",
    "IQR=df['clip_duration'].describe()[6]-df['clip_duration'].describe()[4]\n",
    "IQR2=IQR*1.5\n",
    "threshold=df['clip_duration'].describe()[6]+IQR2\n",
    "for i in range(shape):\n",
    "    if(df.iloc[i, 1:2].values[0] >= threshold):\n",
    "        df.iloc[i, 1:2]=np.nan\n",
    "        #df.at[i, 3:4] = 0\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['clip_filename'], axis=1);\n",
    "\n",
    "X = np.array(df.drop(['encode_vmaf'], 1))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['encode_vmaf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Create SVR model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR = svm.SVR()\n",
    "SVR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence = SVR.score(X_test, y_test)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_SVR=SVR.predict(X_test)\n",
    "plt.scatter(y_test,predict_SVR)\n",
    "plt.xlabel('Calculated vmaf')\n",
    "plt.ylabel('Predicted vmaf')\n",
    "plt.title('SVR Regression')\n",
    "df_svr = pd.concat([pd.DataFrame(y_test) ,pd.DataFrame(predict_SVR)], axis = 1);\n",
    "df_svr.to_excel('SVR_Regression.xlsx');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Corr_SVR',np.corrcoef(y_test , predict_SVR)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate the MSE and RMSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_SVR = MSE(y_test, predict_SVR)\n",
    "print('MSE: %f' % MSE_SVR)\n",
    "\n",
    "rmse_SVR = sqrt(MSE_SVR)\n",
    "print('RMSE: %f' % rmse_SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Linear Regression model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LiReg = LinearRegression()\n",
    "LiReg.fit(X_train, y_train)\n",
    "confidence_LiReg = LiReg.score(X_test, y_test)\n",
    "print(confidence_LiReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_LiReg=LiReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test,predict_LiReg)\n",
    "plt.xlabel('Calculated vmaf')\n",
    "plt.ylabel('Predicted vmaf')\n",
    "plt.title('Linear Regression')\n",
    "\n",
    "df_lin = pd.concat([pd.DataFrame(y_test) ,pd.DataFrame(predict_LiReg)], axis = 1);\n",
    "df_lin.to_excel('Linear_Regression.xlsx');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Calculate the correlation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Corr_Li',np.corrcoef(y_test , predict_LiReg)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Calculate the MSE and RMSE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_Li=MSE(y_test, predict_LiReg)\n",
    "print('MSE: %f' % MSE_Li)\n",
    "rmse_Li = sqrt(MSE_Li)\n",
    "print('RMSE: %f' % rmse_Li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Random Forest model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "confidence_rf = rf.score(X_test, y_test)\n",
    "print(confidence_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rf=rf.predict(X_test)\n",
    "plt.scatter(y_test,predict_rf)\n",
    "plt.xlabel('Calculated vmaf')\n",
    "plt.ylabel('Predicted vmaf')\n",
    "plt.title('Random Forest Regression')\n",
    "df_rf = pd.concat([pd.DataFrame(y_test) ,pd.DataFrame(predict_rf)], axis = 1);\n",
    "df_rf.to_excel('RF_Regression.xlsx');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Calculate the MSE and RMSE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Corr_rf',np.corrcoef(y_test , predict_rf)[0][1])\n",
    "MSE_rf = MSE(y_test, predict_rf)\n",
    "print('MSE: %f' % MSE_rf)\n",
    "rmse_rf = sqrt(MSE_rf)\n",
    "print('RMSE: %f' % rmse_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
